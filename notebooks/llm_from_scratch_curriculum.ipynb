{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM from Scratch - Hands-On Curriculum\n",
    "\n",
    "This Jupyter notebook provides hands-on exercises for implementing a Large Language Model from scratch using PyTorch.\n",
    "\n",
    "## Part 1: Core Transformer Architecture\n",
    "\n",
    "In this exercise, you'll implement the fundamental components of a Transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src to path to import our modules\n",
    "sys.path.append(os.path.join(os.path.dirname(__file__), '..'))\n",
    "\n",
    "# Import our implementations\n",
    "from src.models.attention import MultiHeadAttention\n",
    "from src.models.mlp import MLP\n",
    "from src.models.normalization import LayerNorm\n",
    "from src.models.transformer import TransformerBlock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.1: Implement Basic Attention Mechanism\n",
    "\n",
    "Implement a basic scaled dot-product attention mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask=None):\n",
    "    \"\"\"\n",
    "    Compute scaled dot-product attention.\n",
    "    \n",
    "    Args:\n",
    "        query: Query tensor of shape (batch_size, num_heads, seq_length, head_dim)\n",
    "        key: Key tensor of shape (batch_size, num_heads, seq_length, head_dim)\n",
    "        value: Value tensor of shape (batch_size, num_heads, seq_length, head_dim)\n",
    "        mask: Optional mask tensor\n",
    "        \n",
    "    Returns:\n",
    "        Output tensor and attention weights\n",
    "    \"\"\"\n",
    "    # TODO: Implement scaled dot-product attention\n",
    "    # 1. Compute attention scores: Q @ K^T\n",
    "    # 2. Scale by sqrt(head_dim)\n",
    "    # 3. Apply mask if provided\n",
    "    # 4. Apply softmax\n",
    "    # 5. Apply attention to values: attention @ V\n",
    "    \n",
    "    # Your implementation here\n",
    "    pass\n",
    "\n",
    "# Test your implementation\n",
    "batch_size, num_heads, seq_length, head_dim = 2, 4, 8, 16\n",
    "query = torch.randn(batch_size, num_heads, seq_length, head_dim)\n",
    "key = torch.randn(batch_size, num_heads, seq_length, head_dim)\n",
    "value = torch.randn(batch_size, num_heads, seq_length, head_dim)\n",
    "\n",
    "# output, attention_weights = scaled_dot_product_attention(query, key, value)\n",
    "# print(f\"Output shape: {output.shape}\")\n",
    "# print(f\"Attention weights shape: {attention_weights.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.2: Implement Multi-Head Attention\n",
    "\n",
    "Use our provided MultiHeadAttention class to process sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multi-head attention\n",
    "d_model = 128\n",
    "num_heads = 8\n",
    "attention = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
    "\n",
    "# Create sample input\n",
    "batch_size, seq_length = 2, 10\n",
    "query = torch.randn(batch_size, seq_length, d_model)\n",
    "key = torch.randn(batch_size, seq_length, d_model)\n",
    "value = torch.randn(batch_size, seq_length, d_model)\n",
    "\n",
    "# Process with multi-head attention\n",
    "output, attention_weights = attention(query, key, value)\n",
    "\n",
    "print(f\"Input shape: {query.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Attention weights shape: {attention_weights.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.3: Implement Transformer Block\n",
    "\n",
    "Combine attention, MLP, and normalization to create a complete transformer block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transformer block\n",
    "transformer_block = TransformerBlock(d_model=128, num_heads=8, dropout=0.1)\n",
    "\n",
    "# Create sample input\n",
    "batch_size, seq_length, d_model = 2, 10, 128\n",
    "x = torch.randn(batch_size, seq_length, d_model)\n",
    "\n",
    "# Process with transformer block\n",
    "output = transformer_block(x)\n",
    "\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Training a Tiny LLM\n",
    "\n",
    "In this exercise, you'll train a small language model on sample text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tokenizers.byte_level import ByteLevelTokenizer\n",
    "from src.train.data import create_dataloader\n",
    "from src.train.trainer import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.1: Implement Byte-Level Tokenization\n",
    "\n",
    "Use our byte-level tokenizer to encode and decode text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokenizer\n",
    "tokenizer = ByteLevelTokenizer()\n",
    "\n",
    "# Test encoding and decoding\n",
    "text = \"Hello, world! This is a test.\"\n",
    "encoded = tokenizer.encode(text)\n",
    "decoded = tokenizer.decode(encoded)\n",
    "\n",
    "print(f\"Original text: {text}\")\n",
    "print(f\"Encoded: {encoded}\")\n",
    "print(f\"Decoded: {decoded}\")\n",
    "print(f\"Match: {text == decoded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.2: Create and Train a Tiny LLM\n",
    "\n",
    "Create a simple language model and train it on sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyLLM(nn.Module):\n",
    "    def __init__(self, vocab_size=256, d_model=128, num_heads=8, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerBlock(d_model, num_heads, dropout=0.1)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.output_projection = nn.Linear(d_model, vocab_size)\n",
    "        \n",
    "    def forward(self, input_ids, labels=None):\n",
    "        x = self.embedding(input_ids)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        logits = self.output_projection(x)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            # Shift for next-token prediction\n",
    "            shift_logits = logits[..., :-1, :].contiguous()\n",
    "            shift_labels = labels[..., 1:].contiguous()\n",
    "            loss = F.cross_entropy(\n",
    "                shift_logits.view(-1, shift_logits.size(-1)),\n",
    "                shift_labels.view(-1),\n",
    "                ignore_index=-100\n",
    "            )\n",
    "            \n",
    "        class Output:\n",
    "            def __init__(self, logits, loss):\n",
    "                self.logits = logits\n",
    "                self.loss = loss\n",
    "        return Output(logits, loss)\n",
    "\n",
    "# Create sample data\n",
    "texts = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"Machine learning is a subset of artificial intelligence.\",\n",
    "    \"Natural language processing enables computers to understand text.\",\n",
    "    \"Deep learning models have revolutionized many fields.\",\n",
    "    \"Transformers are the foundation of modern language models.\"\n",
    "]\n",
    "\n",
    "# Create model\n",
    "model = TinyLLM(vocab_size=256, d_model=128, num_heads=8, num_layers=2)\n",
    "\n",
    "# Create dataloader\n",
    "dataloader = create_dataloader(texts, batch_size=2, seq_length=32)\n",
    "\n",
    "# Print model information\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model parameters: {total_params:,}\")\n",
    "\n",
    "# Note: Training would go here in a complete implementation\n",
    "print(\"Model created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Modern Architecture Improvements\n",
    "\n",
    "In this exercise, you'll explore modern improvements to the Transformer architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.normalization import RMSNorm\n",
    "from src.models.positional import RotaryPositionalEncoding\n",
    "from src.models.mlp import SwiGLUMLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1: Compare LayerNorm and RMSNorm\n",
    "\n",
    "Compare the behavior of LayerNorm and RMSNorm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create normalization layers\n",
    "layer_norm = LayerNorm(d_model=128)\n",
    "rms_norm = RMSNorm(d_model=128)\n",
    "\n",
    "# Create sample input\n",
    "batch_size, seq_length, d_model = 2, 10, 128\n",
    "x = torch.randn(batch_size, seq_length, d_model)\n",
    "\n",
    "# Apply normalization\n",
    "ln_output = layer_norm(x)\n",
    "rms_output = rms_norm(x)\n",
    "\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"LayerNorm output shape: {ln_output.shape}\")\n",
    "print(f\"RMSNorm output shape: {rms_output.shape}\")\n",
    "\n",
    "# Check normalization properties\n",
    "ln_mean = ln_output.mean(dim=-1)\n",
    "ln_std = ln_output.std(dim=-1)\n",
    "rms_mean = rms_output.mean(dim=-1)\n",
    "rms_std = rms_output.std(dim=-1)\n",
    "\n",
    "print(f\"LayerNorm mean (should be ~0): {ln_mean.mean():.6f}\")\n",
    "print(f\"LayerNorm std (should be ~1): {ln_std.mean():.6f}\")\n",
    "print(f\"RMSNorm mean: {rms_mean.mean():.6f}\")\n",
    "print(f\"RMSNorm std (should be ~1): {rms_std.mean():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.2: Implement Rotary Positional Encoding\n",
    "\n",
    "Use Rotary Positional Encoding (RoPE) to add positional information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RoPE\n",
    "rope = RotaryPositionalEncoding(d_model=128, max_seq_length=512)\n",
    "\n",
    "# Create sample input\n",
    "batch_size, seq_length, d_model = 2, 10, 128\n",
    "x = torch.randn(batch_size, seq_length, d_model)\n",
    "\n",
    "# Apply RoPE\n",
    "x_with_rope = rope(x)\n",
    "\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {x_with_rope.shape}\")\n",
    "print(f\"RoPE applied successfully: {not torch.allclose(x, x_with_rope)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Scaling Up\n",
    "\n",
    "In this exercise, you'll work with BPE tokenization and advanced training techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tokenizers.bpe import BPE Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.1: Train BPE Tokenizer\n",
    "\n",
    "Train a BPE tokenizer on sample text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample training data\n",
    "training_texts = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"Machine learning is a subset of artificial intelligence.\",\n",
    "    \"Natural language processing enables computers to understand text.\",\n",
    "    \"Deep learning models have revolutionized many fields.\",\n",
    "    \"Transformers are the foundation of modern language models.\",\n",
    "    \"Large language models can generate human-like text.\",\n",
    "    \"Attention mechanisms help models focus on relevant information.\",\n",
    "    \"Neural networks learn patterns from data.\",\n",
    "    \"PyTorch provides flexible tools for deep learning research.\",\n",
    "    \"Open-source software accelerates scientific progress.\"\n",
    "]\n",
    "\n",
    "# Create and train BPE tokenizer\n",
    "bpe_tokenizer = BPE Tokenizer(vocab_size=500)\n",
    "bpe_tokenizer.train(training_texts)\n",
    "\n",
    "# Test tokenization\n",
    "test_text = \"Transformers are powerful models for NLP tasks.\"\n",
    "encoded = bpe_tokenizer.encode(test_text)\n",
    "decoded = bpe_tokenizer.decode(encoded)\n",
    "\n",
    "print(f\"Original: {test_text}\")\n",
    "print(f\"Encoded: {encoded}\")\n",
    "print(f\"Decoded: {decoded}\")\n",
    "print(f\"Vocabulary size: {bpe_tokenizer.vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Mixture of Experts\n",
    "\n",
    "In this exercise, you'll implement and experiment with Mixture of Experts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.moe.gating import TopKGating\n",
    "from src.moe.expert import Expert\n",
    "from src.moe.moe_layer import MoELayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.1: Implement Top-K Gating\n",
    "\n",
    "Implement and test a Top-K gating mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create gating network\n",
    "gating = TopKGating(input_size=128, num_experts=4, k=2)\n",
    "\n",
    "# Create sample input\n",
    "batch_size, seq_length, input_size = 2, 10, 128\n",
    "x = torch.randn(batch_size, seq_length, input_size)\n",
    "\n",
    "# Apply gating\n",
    "gate_logits, gate_weights, expert_indices = gating(x)\n",
    "\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Gate logits shape: {gate_logits.shape}\")\n",
    "print(f\"Gate weights shape: {gate_weights.shape}\")\n",
    "print(f\"Expert indices shape: {expert_indices.shape}\")\n",
    "\n",
    "# Check properties\n",
    "print(f\"Top-K: {expert_indices.shape[-1]}\")\n",
    "print(f\"Weights sum to 1: {torch.allclose(gate_weights.sum(dim=-1), torch.ones_like(gate_weights.sum(dim=-1)))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.2: Create MoE Layer\n",
    "\n",
    "Create and test a Mixture of Experts layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MoE layer\n",
    "moe_layer = MoELayer(\n",
    "    input_size=128,\n",
    "    hidden_size=256,\n",
    "    output_size=128,\n",
    "    num_experts=4,\n",
    "    k=2\n",
    ")\n",
    "\n",
    "# Create sample input\n",
    "batch_size, seq_length, input_size = 2, 10, 128\n",
    "x = torch.randn(batch_size, seq_length, input_size)\n",
    "\n",
    "# Apply MoE\n",
    "output, aux_loss = moe_layer(x)\n",
    "\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Auxiliary loss: {aux_loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Supervised Fine-Tuning\n",
    "\n",
    "In this exercise, you'll work with instruction datasets and fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sft.instruction_data import InstructionDataset\n",
    "from src.sft.loss import CausalLMLossWithMasking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.1: Create Instruction Dataset\n",
    "\n",
    "Create and process an instruction dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample instruction data\n",
    "instructions = [\n",
    "    (\"What is 2+2?\", \"2+2 equals 4.\"),\n",
    "    (\"How many days in a week?\", \"There are 7 days in a week.\"),\n",
    "    (\"What is the capital of France?\", \"The capital of France is Paris.\"),\n",
    "    (\"Who wrote Romeo and Juliet?\", \"William Shakespeare wrote Romeo and Juliet.\"),\n",
    "    (\"What is the largest planet?\", \"Jupiter is the largest planet in our solar system.\")\n",
    "]\n",
    "\n",
    "# Create dataset\n",
    "dataset = InstructionDataset(instructions)\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "\n",
    "# Test data retrieval\n",
    "sample = dataset[0]\n",
    "print(f\"Sample format: {type(sample)}\")\n",
    "if isinstance(sample, tuple):\n",
    "    print(f\"Sample length: {len(sample)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Reward Modeling\n",
    "\n",
    "In this exercise, you'll work with preference datasets and reward models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.reward.preference_data import PreferenceExample\n",
    "from src.reward.model import RewardModel\n",
    "from src.reward.loss import BradleyTerryLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7.1: Create Preference Dataset\n",
    "\n",
    "Create and work with preference examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preference examples\n",
    "examples = [\n",
    "    PreferenceExample(\n",
    "        prompt=\"How do you make a cake?\",\n",
    "        chosen_response=\"First, gather ingredients like flour, eggs, and sugar. Then mix them together and bake.\",\n",
    "        rejected_response=\"You eat it raw.\",\n",
    "        chosen_score=0.9,\n",
    "        rejected_score=0.1\n",
    "    ),\n",
    "    PreferenceExample(\n",
    "        prompt=\"What is the weather like?\",\n",
    "        chosen_response=\"It's sunny and warm today with clear skies.\",\n",
    "        rejected_response=\"I don't know.\",\n",
    "        chosen_score=0.8,\n",
    "        rejected_score=0.2\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"Created {len(examples)} preference examples\")\n",
    "for i, example in enumerate(examples):\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"  Prompt: {example.prompt}\")\n",
    "    print(f\"  Chosen: {example.chosen_response}\")\n",
    "    print(f\"  Rejected: {example.rejected_response}\")\n",
    "    print(f\"  Chosen Score: {example.chosen_score}\")\n",
    "    print(f\"  Rejected Score: {example.rejected_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7.2: Implement Reward Model\n",
    "\n",
    "Create and test a reward model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple base model for the reward model\n",
    "class SimpleBaseModel(nn.Module):\n",
    "    def __init__(self, hidden_size=128, vocab_size=1000):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        x = self.embedding(input_ids)\n",
    "        x = self.linear(x)\n",
    "        logits = torch.randn(input_ids.shape[0], input_ids.shape[1], 1000)\n",
    "        \n",
    "        class MockOutput:\n",
    "            def __init__(self, last_hidden_state, logits):\n",
    "                self.last_hidden_state = last_hidden_state\n",
    "                self.logits = logits\n",
    "        return MockOutput(x, logits)\n",
    "\n",
    "# Create base model\n",
    "base_model = SimpleBaseModel(hidden_size=128, vocab_size=1000)\n",
    "\n",
    "# Create reward model\n",
    "reward_model = RewardModel(base_model, hidden_size=128)\n",
    "\n",
    "# Create sample input\n",
    "batch_size, seq_length = 2, 20\n",
    "input_ids = torch.randint(0, 1000, (batch_size, seq_length))\n",
    "\n",
    "# Get rewards\n",
    "rewards = reward_model(input_ids)\n",
    "\n",
    "print(f\"Input shape: {input_ids.shape}\")\n",
    "print(f\"Rewards shape: {rewards.shape}\")\n",
    "print(f\"Rewards: {rewards}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: RLHF with PPO\n",
    "\n",
    "In this exercise, you'll work with PPO for reinforcement learning from human feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.rlhf.ppo import PolicyValueNetwork, PPOTrainer, PPOConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8.1: Create PPO Configuration\n",
    "\n",
    "Create and examine PPO configuration parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PPO configuration\n",
    "config = PPOConfig(\n",
    "    ppo_epochs=4,\n",
    "    batch_size=8,\n",
    "    clip_epsilon=0.2,\n",
    "    learning_rate=1e-5\n",
    ")\n",
    "\n",
    "print(\"PPO Configuration:\")\n",
    "print(f\"  PPO Epochs: {config.ppo_epochs}\")\n",
    "print(f\"  Batch Size: {config.batch_size}\")\n",
    "print(f\"  Clip Epsilon: {config.clip_epsilon}\")\n",
    "print(f\"  Learning Rate: {config.learning_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: RLHF with GRPO\n",
    "\n",
    "In this exercise, you'll work with GRPO (Group-Relative Policy Optimization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.rlhf.grpo import GRPOTrainer, GRPOConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9.1: Create GRPO Configuration\n",
    "\n",
    "Create and examine GRPO configuration parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GRPO configuration\n",
    "config = GRPOConfig(\n",
    "    grpo_epochs=4,\n",
    "    batch_size=8,\n",
    "    num_completions_per_prompt=4,\n",
    "    group_size=4\n",
    ")\n",
    "\n",
    "print(\"GRPO Configuration:\")\n",
    "print(f\"  GRPO Epochs: {config.grpo_epochs}\")\n",
    "print(f\"  Batch Size: {config.batch_size}\")\n",
    "print(f\"  Completions per Prompt: {config.num_completions_per_prompt}\")\n",
    "print(f\"  Group Size: {config.group_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 10: Advanced Semantic Processing\n",
    "\n",
    "In this exercise, you'll work with advanced semantic processing techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.semantic.processing import SemanticConfig, SemanticProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10.1: Create Semantic Configuration\n",
    "\n",
    "Create and examine semantic processing configuration parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create semantic configuration\n",
    "config = SemanticConfig(\n",
    "    hidden_size=768,\n",
    "    concept_dim=512,\n",
    "    num_concepts=1024,\n",
    "    hyperbolic_dim=128\n",
    ")\n",
    "\n",
    "print(\"Semantic Processing Configuration:\")\n",
    "print(f\"  Hidden Size: {config.hidden_size}\")\n",
    "print(f\"  Concept Dimension: {config.concept_dim}\")\n",
    "print(f\"  Number of Concepts: {config.num_concepts}\")\n",
    "print(f\"  Hyperbolic Dimension: {config.hyperbolic_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficiency Optimizations\n",
    "\n",
    "In this exercise, you'll work with quantization and compression techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.quantization import apply_quantization\n",
    "from src.utils.compression import apply_pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Apply Model Quantization\n",
    "\n",
    "Apply quantization to reduce model size and improve inference speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple model for demonstration\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(128, 256)\n",
    "        self.linear2 = nn.Linear(256, 128)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "# Create original model\n",
    "original_model = SimpleModel()\n",
    "original_size = sum(p.numel() for p in original_model.parameters())\n",
    "\n",
    "print(f\"Original model parameters: {original_size:,}\")\n",
    "\n",
    "# Apply 8-bit quantization\n",
    "quantized_model = apply_quantization(original_model, bits=8)\n",
    "quantized_size = sum(p.numel() for p in quantized_model.parameters())\n",
    "\n",
    "print(f\"Quantized model parameters: {quantized_size:,}\")\n",
    "print(f\"Compression ratio: {original_size / quantized_size:.2f}x\")\n",
    "\n",
    "# Apply pruning\n",
    "pruned_model = apply_pruning(original_model, sparsity_ratio=0.5)\n",
    "pruned_size = sum(p.numel() for p in pruned_model.parameters())\n",
    "\n",
    "print(f\"Pruned model parameters: {pruned_size:,}\")\n",
    "print(f\"Pruning compression ratio: {original_size / pruned_size:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook has provided hands-on exercises covering all 10 parts of the LLM from Scratch curriculum:\n",
    "\n",
    "1. Core Transformer Architecture\n",
    "2. Training a Tiny LLM\n",
    "3. Modern Architecture Improvements\n",
    "4. Scaling Up\n",
    "5. Mixture of Experts\n",
    "6. Supervised Fine-Tuning\n",
    "7. Reward Modeling\n",
    "8. RLHF with PPO\n",
    "9. RLHF with GRPO\n",
    "10. Advanced Semantic Processing\n",
    "\n",
    "You've also explored efficiency optimization techniques like quantization and pruning.\n",
    "\n",
    "Each exercise builds upon the previous ones, providing a comprehensive understanding of modern LLM implementation techniques."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}