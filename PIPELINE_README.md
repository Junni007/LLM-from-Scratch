# LLM Training Pipeline

This directory contains an organized pipeline for training and using your own LLM from scratch.

## Directory Structure

```
├── datasets/              # Put all your training data here
│   ├── text/              # Plain text files (.txt)
│   ├── json/              # JSON files with text data
│   ├── csv/               # CSV files with text data
│   ├── custom/            # Custom format files
│   └── sample_data.txt    # Sample dataset file (legacy location)
├── outputs/               # All outputs will be saved here
│   ├── llm_model.pth      # Trained model checkpoint
│   └── generated_samples.txt  # Sample generated text
├── run_llm_pipeline.py    # Main pipeline runner
└── ... (other project files)
```

## How to Use

### 1. Prepare Your Datasets

Place all your text training data in the appropriate subdirectories under `datasets/`:
- `datasets/text/` - Plain text files (.txt)
- `datasets/json/` - JSON files containing text data
- `datasets/csv/` - CSV files with text data
- `datasets/custom/` - Custom format files

The system supports multiple dataset formats:
- **Text files**: Plain .txt files with one or more text samples
- **JSON files**: Files containing arrays of text strings or objects with 'text' fields
- **CSV files**: Files with a 'text' column or first column containing text
- **Custom files**: Any other format placed in the custom directory

### 2. Run the Complete Pipeline

```bash
python run_llm_pipeline.py
```

This will:
1. Load all datasets from the `datasets/` directory and its subdirectories
2. Train the LLM model on your data
3. Save the trained model to `outputs/llm_model.pth`
4. Generate sample text outputs and save them to `outputs/generated_samples.txt`

### 3. Customization Options

You can modify the training parameters in `run_llm_pipeline.py`:
- Model size (d_model, num_heads, num_layers)
- Training epochs
- Batch size
- Learning rate

## Output Files

After running the pipeline, you'll find:
- `outputs/llm_model.pth`: The trained model checkpoint
- `outputs/generated_samples.txt`: Sample text generated by your model

## Requirements

Make sure you have installed all dependencies:
```bash
pip install -r requirements.txt
```

## Example Usage

```python
# Run with default settings
python run_llm_pipeline.py

# The trained model will be saved in outputs/llm_model.pth
# Sample generations will be saved in outputs/generated_samples.txt
```

## Notes

- Training time depends on your dataset size and hardware
- Larger models require more memory and training time
- GPU acceleration is automatically used if available
- For large datasets, consider adjusting batch size and sequence length